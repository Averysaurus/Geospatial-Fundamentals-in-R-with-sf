---
title: An R Markdown document converted from "./07_Joins_and_Aggregation.ipynb"
output: html_document
---

# Lesson 7. Attribute and Spatial Joins

Now that we understand the logic of spatial relationship queries,
let's take a look at another fundamental spatial operation that relies on them.

This operation, called a **spatial join**, is the process by which we can
leverage the spatial relationships between distinct datasets to merge
their information into a new, synthetic dataset.

This operation can be thought as the spatial equivalent of an
**attribute join**, in which multiple tabular datasets can be merged by
aligning matching values in a common column that they both contain.
Thus, we'll start by developing an understanding of this operation first!

- 7.0 Data Input and Prep
- 7.1 Attribute Joins
- **Exercise**: Choropleth Map
- 7.2 Spatial Joins
- 7.3 Aggregation
- **Exercise**: Aggregation
- 7.4 Recap

<br>
<font color='grey'>
    <b>Instructor Notes</b>

- Datasets used
    - 'notebook_data/census/ACS5yr/census_variables_CA.csv'
    - 'notebook_data/census/Tracts/cb_2013_06_tract_500k.zip'
    - 'notebook_data/alco_schools.csv'
    
- Expected time to complete
    - Lecture + Questions: 45 minutes
    - Exercises: 20 minutes
</font>

```{r}
library(sf)
library(tmap)
```

# 7.0 Data Input and Prep

Let's read in a table of data from the US Census' 5-year American Community Survey (ACS5).

```{r}
# Read in the ACS5 data for CA into an `sf` object.
# Note: We force the FIPS_11_digit to be read in as a string to preserve any leading zeroes.
acs5_df = read.csv("notebook_data/census/ACS5yr/census_variables_CA.csv")
head(acs5_df)
```

**Brief summary of the data**:

Below is a table of the variables in this table. They were combined from 
different ACS 5 year tables.

<u>NOTE</u>:
- variables that start with `c_` are counts
- variables that start with `med_` are medians
- variables that end in `_moe` are margin of error estimates
- variables that start with `_p` are proportions calcuated from the counts divided by the table denominator (the total count for whom that variable was assessed)


| Variable        | Description                                     |
|-----------------|-------------------------------------------------|
|`c_race`         |Total population                                 
|`c_white`        |Total white non-Latinx
| `c_black`       | Total black and African American non-Latinx
| `c_asian`       | Total Asian non-Latinx
| `c_latinx`      | Total Latinx
| `state_fips`    | State level FIPS code
| `county_fips`   | County level FIPS code
| `tract_fips`    |Tracts level FIPS code
| `med_rent`      |Median rent
| `med_hhinc`     |Median household income
| `c_tenants`     |Total tenants
| `c_owners`      |Total owners
| `c_renters`     |Total renters
| `c_movers`      |Total number of people who moved
| `c_stay`        |Total number of people who stayed
| `c_movelocal`   |Number of people who moved locally
| `c_movecounty`  |Number of people who moved counties
| `c_movestate`   | Number of people who moved states
| `c_moveabroad`  |Number of people who moved abroad
| `c_commute`     |Total number of commuters
| `c_car`         | Number of commuters who use a car
| `c_carpool`     | Number of commuters who carpool
| `c_transit`     |Number of commuters who use public transit
| `c_bike`        |Number of commuters who bike
| `c_walk`        |Number of commuters who bike
| `year`          | ACS data year
| `FIPS_11_digit` | 11-digit FIPS code

We're going to drop all of our `moe` columns by identifying all of those that end with `_moe`. We can do that in two steps, first by using `filter` to identify columns that contain the string `_moe`.

`tidyverse` will help with this!

```{r}
library(tidyverse) 
acs5_df = acs5_df %>% select(-contains("_moe"))
```

Unfortunately, when this dataset reads in, the 11-digit FIPS codes that should be strings actually read in as numerics, and thus the leading 0 gets truncated. We're going to need those FIPS code in the correct format later, so let's reformat them now.

```{r}
# recast the FIPS 11-digit codes as strings, pasting a 0 at the front of each
acs5_df$FIPS_11_digit = paste0('0', acs5_df$FIPS_11_digit)
```

And lastly, let's grab only the rows for year 2018 and county FIPS code 1 (i.e. Alameda County)

```{r}
acs5_df_ac = acs5_df[acs5_df$year==2018 & acs5_df$county_fips==1, ]
```

```{r}
head(acs5_df_ac)
```




Now let's also read in our census tracts again!

```{r}
tracts_sf = st_read("./notebook_data/census/Tracts/cb_2013_06_tract_500k.shp", )
```

```{r}
head(tracts_sf)
```

```{r}
tracts_sf_ac = tracts_sf[tracts_sf$COUNTYFP == '001',]
plot(tracts_sf_ac$geometry)
```

# 7.1 Attribute Joins

**Attribute Joins  between `sf` data.frames and plain data.frames**

*We just mapped the census tracts. But what makes a map powerful is when you map the data associated with the locations.*

- `tracts_sf_ac`: These are polygon data in an `sf` data.frame. However, as we saw in the `head` of that dataset, they no attributes of interest!

- `acs5_df_ac`: These are 2018 ACS data from a CSV file ('census_variables_CA.csv'), imported and read in as a plain data.frame. However, they have no geometries!

In order to map the ACS data we need to associate it with the tracts. Let's do that now, by joining the columns from `acs5_df_ac` to the columns of `tracts_gdf_ac` using a common column as the key for matching rows. This process is called an **attribute join**.







<img src="https://shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2017/03/join-types-merge-names.jpg">


<img src="http://www.pngall.com/wp-content/uploads/2016/03/Light-Bulb-Free-PNG-Image.png" width="20" align=left >  **Question**

The image above gives us a nice conceptual summary of the types of joins we could run.

1. In general, why might we choose one type of join over another?
1. In our case, do we want an inner, left, right, or outer (AKA 'full') join? 

(**NOTE**: You can read more about merging `sf` and plain data.frames [here](https://r-spatial.github.io/sf/reference/merge.sf.html).)


Okay, here we go!

Let's take a look at the common column in both our data.frames.

```{r}
head(tracts_sf_ac['GEOID'])
```

```{r}
head(acs5_df_ac['FIPS_11_digit'])
```


Note that they are **not named the same thing**. 
        
        That's okay! We just need to know that they contain the same information.

Also note that they are **not in the same order**. 
        
        That's not only okay... That's the point! (If they were in the same order already then we could just join them side by side, without having R find and line up the matching rows from each!)





Let's do a `left` join to keep all of the census tracts in Alameda County and only the ACS data for those tracts.

**NOTE**: To figure out how to do this we could always take a peek at the documentation by calling
`?base::merge`.

```{r}
?base::merge
```

```{r}
# Left join keeps all tracts and the acs data for those tracts
tracts_acs_sf_ac = base::merge(tracts_sf_ac, acs5_df_ac, by.x = 'GEOID', by.y = "FIPS_11_digit", all.x=TRUE)
head(tracts_acs_sf_ac)
```

Let's check that we have all the variables we have in our dataset now.

```{r}
colnames(tracts_acs_sf_ac)
```

<img src="http://www.pngall.com/wp-content/uploads/2016/03/Light-Bulb-Free-PNG-Image.png" width="20" align=left >  **Question**

It's always important to run sanity checks on our results, at each step of the way!

In this case, how many rows and columns should we have?


```{r}
print("Rows and columns in the Alameda County Census tract gdf:")
print(dim(tracts_sf_ac))
print("Row and columns in the ACS5 2018 data:")
print(dim(acs5_df_ac))
print("Rows and columns in the Alameda County Census tract gdf joined to the ACS data:")
print(dim(tracts_acs_sf_ac))
```

Let's save out our merged data so we can use it in the final notebook.

```{r}
st_write(tracts_acs_sf_ac, './outdata/tracts_acs_gdf_ac.json', driver='GeoJSON', delete_dsn=T)
```

## Exercise: Choropleth Map
We can now make choropleth maps using our attribute joined geodataframe. Go ahead and pick one variable to color the map, then map it using `tmap` (since it's too easy using the `plot` method). You can go back to lesson 5 if you need a refresher on how to make this!

To see the solution, look at the hidden text below.

```{r}
head(tracts_acs_sf_ac)
```

```{r}
# YOUR CODE HERE





```

## Solution hidden here!

<!--

# SOLUTION:
tm_shape(tracts_acs_sf_ac) + 
  tm_polygons(col = 'p_renters',
              style = 'quantile',
              palette = 'PuBuGn',
              title = 'Percentage of Renters')


-->


# 7.2 Spatial Joins

Great! We've wrapped our heads around the concept of an attribute join.

Now let's extend that concept to its spatially explicit equivalent: the **spatial join**!


<br>

To start, we'll read in some other data: The Alameda County schools data.

Then we'll work with that data and our `tracts_acs_sf_ac` data together.

```{r}
schools_df = read.csv('notebook_data/alco_schools.csv')
schools_sf = st_as_sf(schools_df, coords = c('X', 'Y'), crs=4326)
```

Let's check if we have to transform the schools to match the`tracts_acs_sf_ac`'s CRS.

```{r}
print('schools_sf CRS:')
print(st_crs(schools_sf))
print('tracts_acs_sf_ac CRS:')
print(st_crs(tracts_acs_sf_ac))
```

Yes we do! Let's do that.

**NOTE**: Explicit syntax aiming at that dataset's CRS leaves less room for human error!

```{r}
schools_sf = st_transform(schools_sf, st_crs(tracts_acs_sf_ac))

print('schools_sf CRS:')
print(st_crs(schools_sf))
print('tracts_acs_sf_ac CRS:')
print(st_crs(tracts_acs_sf_ac))
```

Now we're ready to combine the datasets in an analysis.

**In this case, we want to get data from the census tract within which each school is located.**

But how can we do that? The two datasets don't share a common column to use for a join.

```{r}
colnames(tracts_acs_sf_ac)
```

```{r}
colnames(schools_sf)
```

However, they do have a shared relationship by way of space! 

So, we'll use a spatial relationship query to figure out the census tract that
each school is in, then associate the tract's data with that school (as additional data in the school's row).
This is a **spatial join**!




### Census Tract Data Associated with Each School

In this case, let's say we're interested in the relationship between the median household income
in a census tract (`tracts_acs_sf_ac$med_hhinc`) and a school's Academic Performance Index
(`schools_gdf$API`).

To start, let's take a look at the distributions of our two variables of interest.

```{r}
head(tracts_acs_sf_ac)
```

```{r}
hist(tracts_acs_sf_ac$med_hhinc)
```

```{r}
hist(schools_sf$API)
```

Oh, right! Those pesky schools with no reported APIs (i.e. API == 0)! Let's drop those.

```{r}
schools_sf_api = schools_sf[schools_sf$API > 0, ]
```

```{r}
hist(schools_sf_api$API)
```

Much better!

Now, maybe we think there ought to be some correlation between the two variables?
As a first pass at this possibility, let's overlay the two datasets, coloring each one by
its variable of interest. This should give us a sense of whether or not similar values co-occur.

```{r}
tm_shape(tracts_acs_sf_ac) + 
  tm_polygons(col = 'med_hhinc',
             palette = 'RdPu') + 
tm_shape(schools_sf_api) + 
  tm_dots(col = 'API',
          palette = 'RdPu',
          size = 0.15)
```

### Spatially Joining our Schools and Census Tracts

Though it's hard to say for sure, it certainly looks possible.
It would be ideal to scatterplot the variables! But in order to do that, 
we need to know the median household income in each school's tract, which
means we definitely need our **spatial join**!

We'll first take a look at the documentation for the spatial join function, `st_join`.

```{r}
?st_join
```

Looks like the key arguments to consider are:
- the two `sf` data.frames (**`x`** and **`y`**)
- the type of join to run (**`left`**), which is a left join if `TRUE`, or an inner join if `FALSE`
- the spatial relationship query to use (**`join`**)

**NOTE**:
- By default `st_join` is a left join, because `left` defaults to TRUE. 

- By default `st_join` maintains the geometries of the first `sf` data.frame input to the operation (i.e. the geometries of `x`). 

<img src="http://www.pngall.com/wp-content/uploads/2016/03/Light-Bulb-Free-PNG-Image.png" width="20" align=left >  **Question**

1. Which `sf` data.frame are we joining onto which (i.e. which one is getting the other one's data added to it)?
2. What happened to 'outer' as a join type?
3. Thus, in our operation, which `sf` data.frame should be `x`, which should be `y`, and should `left` be `TRUE` or `FALSE`?


Alright! Let's run our join!

```{r}
schools_jointracts = st_join(schools_sf_api, tracts_acs_sf_ac, left=T, join=st_within)
```

### Checking Our Output

<br>

<img src="http://www.pngall.com/wp-content/uploads/2016/03/Light-Bulb-Free-PNG-Image.png" width="20" align=left >  **Question**

As always, we want to sanity-check our intermediate result before we rush ahead.

One way to do that is to introspect the structure of the result object a bit.

1. What type of object should that have given us?
2. What should the dimensions of that object be, and why?
3. If we wanted a visual check of our results (i.e. a plot or map), what could we do?


```{r}
print(dim(schools_jointracts))
print(dim(schools_sf))
print(dim(tracts_acs_sf_ac))
```

```{r}
head(schools_jointracts)
```

Confirmed! The output of the our `st_join` operation is an `sf` data.frame (`schools_jointracts`) with:
- a row for each school that is located inside a census tract (all of them are)
- the **point geometry** of that school
- all of the attribute data columns (non-geometry columns) from both input `sf` data.frames



Let's also take a look at an overlay map of the schools on the tracts.
If we color the schools categorically by their tracts IDs, then we should see
that all schools within a given tract polygon are the same color.

```{r}
tm_shape(tracts_acs_sf_ac) + 
  tm_polygons(col='white', border.col='black') + 
tm_shape(schools_jointracts) + 
  tm_dots(col='GEOID', size=0.2)
```

### Assessing the Relationship between Median Household Income and API

Fantastic! That looks right!

Now we can create that scatterplot we were thinking about!

```{r}
plot(schools_jointracts$med_hhinc, schools_jointracts$API,
     xlab = 'median household income ($)',
     ylab = 'API')
```

Wow! Just as we suspected based on our overlay map,
there's a pretty obvious, strong, and positive correlation
between median household income in a school's tract
and the school's API.

# 7.3: Aggregation

We just saw that a spatial join in one way to leverage the spatial relationship
between two datasets in order to create a new, synthetic dataset.

An **aggregation** is another way we can generate new data from this relationship.
In this case, for each feature in one dataset we find all the features in another
dataset that satisfy our chosen spatial relationship query with it (e.g. within, intersects),
then aggregate them using some summary function (e.g. count, mean).




### Getting the Aggregated School Counts

Let's take this for a spin with our data. We'll count all the schools within each census tract.

We could do this using an aspatial group-by operation on the GEOID column of the new, spatially joined dataset that we just made. However, since we're in a geospatial workshop let's use a spatial aggregation instead!

(Also, to get the correct count, lets use all our schools, not just those with APIs > 0.)

```{r}
schools_for_count = schools_sf['geometry']
schools_for_count$count = 1
schools_countsbytract = sf:::aggregate.sf(x=schools_for_count, by=tracts_acs_sf_ac, FUN=sum)
```

Let's see what we got out.

```{r}
print("Counts, rows and columns:")
print(dim(schools_countsbytract))
print("Tracts, rows and columns:")
print(dim(tracts_acs_sf_ac))

# take a look at the data
head(schools_countsbytract)
```

<img src="http://www.pngall.com/wp-content/uploads/2016/03/Light-Bulb-Free-PNG-Image.png" width="20" align=left >  **Question**

1. Above we selected the geometry column, added a column of 1s, then aggregated. Why?
1. What explains the dimensions of the new object (361, 2)?


### Mapping our Spatial Join Output

As a sanity-check, we can now map the school counts for all census tracts.

```{r}
tm_shape(schools_countsbytract) + 
  tm_polygons(col='count') + 
tm_shape(schools_sf) + 
  tm_dots(col='black', alpha=0.75, size=0.1)
```


# Exercise: Aggregation

#### What is the mean API of each census tract?

As we mentioned, the spatial aggregation workflow that we just put together above
could have been used not to generate a new count variable, but also
to generate any other new variable the results from calling an aggregation function
on an attribute column.

In this case, we want to calculate and map the mean API of the schools in each census tract.

Copy and paste code from above where useful, then tweak and/or add to that code such that your new code:

1. joins the schools onto the tracts (**HINT**: make sure to decide whether or not you want to include schools with API = 0!)
2. dissolves that joined object by the tract IDs, giving you a new GeoDataFrame with each tract's mean API (**HINT**: because this is now a different calculation, different problems may arise and need handling!)
3. plots the tracts, colored by API scores (**HINT**: overlay the schools points again, visualizing them in a way that will help you visually check your results!)

To see the solution, look at the hidden text below.

```{r}
# YOUR CODE HERE:






```

## Solution hidden here!

<!--

# SOLUTION:


tracts_meanAPI = sf:::aggregate.sf(x=schools_sf_api['API'], by=tracts_acs_sf_ac, FUN=mean)

# plot the tracts, coloring them by mean API
tm_shape(tracts_meanAPI) + 
  tm_polygons(col = 'API',
             palette = 'RdYlGn',
             style = 'equal',
             border.col = 'grey',
             title = 'mean API (tracts)') + 
tm_shape(schools_sf_api) + 
  tm_dots(col='API',
          palette='RdYlGn',
          size=0.1,
          title='API (schools)')


-->



## 7.4 Recap
We discussed how we can combine datasets to enhance any geospatial data analyses you could do. Key concepts include:

-  Attribute joins
	- `merge()`
- Spatial joins (order matters!)
	- `st_join`
- Aggregation
	- `aggregate.sf`

---
<div style="display:inline-block;vertical-align:middle;">
<a href="https://dlab.berkeley.edu/" target="_blank"><img src ="assets/images/dlab_logo.png" width="75" align="left">
</a>
</div>

<div style="display:inline-block;vertical-align:middle;">
<div style="font-size:larger">&nbsp;D-Lab @ University of California - Berkeley</div>
<div>&nbsp;Team Geo<div>
</div>
        



